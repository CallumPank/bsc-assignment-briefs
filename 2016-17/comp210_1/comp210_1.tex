\documentclass{../fal_assignment}
\graphicspath{ {../} }

\usepackage{enumitem}
\usepackage[T1]{fontenc} % http://tex.stackexchange.com/a/17858
\usepackage{url}
\usepackage{todonotes}

\title{Interfaces \& Interaction}
\author{Alcwyn Parker}

\begin{document}
\maketitle

\marginpicture{flavour_pic}{
    The \emph{Arduino} is an open-source prototyping platform that makes designing and developing interfaces fun \& easy.}
\section*{Introduction}

In this assignment, you are required to choose an existing screen based game interface to evaluate with a focus on usability and user-experience. Although the choice of game interface is down to you, careful consideration must be given to select an interface that is complex and interesting enough to warrant interrogation. How you evaluate the interface is down to you, although your approach must be appropriate and you will need to provide justification in your documentation. To ensure a thorough evaluation it is advised that you implement at least two distinct methods of evaluation, one qualitative and one quantitative. Some suggested methods are: cognitive walkthrough, task analysis, user-story mapping, analytic tools or any other methods that you feel are relevant. 

Human-centred design (HCD) puts the end-user at the heart of the design process with a focus on usability and user-experience (UX). It relies on a fast-paced, iterative approach to the design and development process where evaluation and testing are built into every iteration. This allows the designer to learn from each iteration and form goals and objectives for the next. It is vital that you familiarise yourself with the various qualitative and quantitive evaluation methods so that you can apply them to all of your future projects.  

This assignment is formed of several parts:

\begin{enumerate}[label=(\alph*)]
    \item \textbf{Implement} a thorough evaluation of a screen based game interface of your choice. Create a GitHub Page to document your evaluation process, that will:
    	\begin{enumerate}[label=\roman*.]
    		\item \textbf{justify} your choice of screen based game interface;
    		\item \textbf{list} and \textbf{justify} your choice of evaluation methods;
		\item \textbf{describe} in great detail, the findings from the evaluation task.
	\end{enumerate}
    \item \textbf{Present}, a ten minute summary of your findings that will:
    	\begin{enumerate}[label=\roman*.]
    		\item \textbf{clarify} your approach to the task;
    		\item \textbf{describe} the strengths and weaknesses of your chosen interface;
    		\item and \textbf{discuss how} strategies derived from your findings that might improve the usability and user-experience of the interface in question.
	\end{enumerate}
	\item As part of your GitHub documentation page, \textbf{Write} a conclusion that will:
    	\begin{enumerate}[label=\roman*.]
    		\item \textbf{synthesise} your findings into a clear and concise list of strengths and weaknesses for your chosen interface. 
    		\item \textbf{reflect} on the process and consider the strengths and weaknesses of your approach;
	\end{enumerate}
\end{enumerate}

\subsection*{Assignment Setup}

This assignment is an \textbf{usability evaluation task}. Fork the GitHub repository at:

\indent \url{https://github.com/Falmouth-Games-Academy/comp210-evaluation}

Use the existing directory structure and, as required, extend this structure with sub-directories. Ensure that you maintain the \texttt{readme.md} file.

Modify the \texttt{.gitignore} to the defaults for \textbf{TeX}. Please, also ensure that you add editor-specific files and folders to \texttt{.gitignore}. 

\subsection*{Part A}

Part A is formed of \textbf{multiple formative submissions}. This is \textbf{individual} work will be assessed on a \textbf{threshold} basis. The following criteria are used to determine a pass or fail:

\begin{enumerate}[label=(\alph*)]
	\item Submission is timely;
	\item Enough progress is made to conduct a meaningful review each week;
\end{enumerate}

To complete Part A, carry out a thorough evaluation of your chosen interface and document your process and findings using GitHub pages.  Demonstrate your progress to your tutor each week in class. At the minimum, you are expected to implement at least one qualitative and one quantitative evaluation method. Ensure that any digital artefacts (including but not limited to sketches, photographs, diagrams, raw data, and any other documentation) are included in your GitHub page. The GitHub pages platform is extremely versatile, with very little effort you should be able to achieve some quite dynamic and creative documentation. Although some textual discussion will be necessary, do not overly rely on this mode of communication. Instead, experiment with embedding dynamic content such as info visualisations, images and videos. You will receive immediate \textbf{informal feedback} from your \textbf{tutor} and \textbf{peers}.

\subsection*{Part B}

Part B is a \textbf{single summative submission}. This is \textbf{individual} work will be assessed on a \textbf{threshold} basis. The following criteria are used to determine a pass or fail: 

\begin{enumerate}[label=(\alph*)]
	\item Enough work is available to hold a meaningful discussion; 
	\item Clear evidence of usability testing knowledge and communication skills; 
	\item No breaches of academic integrity. 
\end{enumerate}

To complete Part B, prepare a ten minute presentation based on around your GitHub documentation page that explains your approach to the task and summarises your findings. Ensure that all related assets are pushed to GitHub and a pull request is made prior to the scheduled viva session. Then, attend the scheduled viva session. %is this necessary?

You will receive \textbf{immediate informal} feedback from your \textbf{tutor} and \textbf{peers}.

\subsection*{Part C}

Part C is a \textbf{single summative submission}. This work is \textbf{individual} and will be assessed on a \textbf{criterion-referenced} basis. Please refer to the marking rubric at the end of this document for further detail.

To complete Part C, write a conclusion that provides a synthesis  of your findings and reflects on the strengths and weakness of your approach to the task. Then, upload all the documentation to the LearningSpace. Please note, the LearningSpace will only accept a single \texttt{.zip} file.

You will receive \textbf{formal feedback} from your \textbf{tutor} three weeks after the final submission deadline.

\section*{Additional Guidance}
Choosing an appropriate game interface is critical to this task. Your choice of game interface should not only be complex and interesting enough to warrant interrogation but also be relevant to your interests and your aspirations as a game developer. The selection process might involve choosing multiple games and using rapid and heavily discounted evaluation methods to identify the game interface that will produce the most insightful results. Before you begin the task you are encourages to research existing case studies/evaluations to inform your approach. 

Your evaluation must find a balance between expert reviews vs. usability testing. As mentioned previously, human-centred design puts the user at the centre of the design process and thus, relying solely on expert review will not produce results conducive to a HCD process. The purpose of usability testing is to evaluate the users behaviour when interacting with an interface and identify the aspects of the interface that are most regularly a source of frustration and confusion. Tests should be designed around tasks and scenarios that represent typical end-user goals. Participants in your studies must span a range of skills and experiences for your results to be meaningful. It is important that you go beyond your course cohort to find participants. 

GitHub pages are an invaluable tool for showcasing your work to future employers and collaborators. You will use them a lot more in the third year so it is important that you familiarise yourself with them now. GitHub pages are created just like any other website, using HTML to layout content, CSS to control the style and JavaScript to create dynamic behaviour such as animations and interactive components. These are very simple mark-up languages and there are many great tutorials available online. You are encouraged to start experimenting with GitHub pages from the very start of this module. Start to map out the structure of your evaluation documentation as soon as possible.  

Poor planning and poor time management can have a significant impact on this assignment. A comprehensive evaluation cannot be `crammed' into a last minute deluge. Sustain a steady pace across the four weeks. At a minimum, you should aim to implement one method of evaluation a week.

Areas where students tend to lose marks are: depth of insight; analytical skill; and evaluative skill. Depth of insight implies rigorous testing of each task in great. Adequate analysis implies going beyond mere description, perhaps through: researching UI/UX, comparing interface, or even deploying reasoning to generate new insights. Adequate evaluation implies making appropriate reference to evidence and ensuring that evidence is of appropriate quality. Further to this, sound and valid arguments are constructed based on common usability principles. 

\begin{marginquote}
    ``The first 90 percent of the code accounts for the first 90 percent of the development time.
    
    ``The remaining 10 percent of the code accounts for the other 90 percent of the development time.''
    
    --- Tom Cargill
    
    \marginquoterule
    
    ``Hofstadter's Law:
    
    ``It always takes longer than you expect, even when you take into account Hofstadter's Law.''
    
    --- Douglas Hofstadter
\end{marginquote}

\section*{Additional Resources}
\begin{itemize}
    \item Guild, John D., and Clayton Lewis. Designing for Usability: Key Principles and What Designers Think. Communications of the ACM, 1985.
    \item Krug, Steve. Don't Make Me Think. Berkeley, 2000. 
    \item Reiss, Eric, Usable Usability : Simple Steps for Making Stuff Better. Wiley, 2012.
\end{itemize}

\begin{markingrubric}
% DONE
    \firstcriterion{Basic Competency Threshold}{40\%}
        \gradespan{1}{\fail At least one part is missing or is unsatisfactory. 
        
        There is little or no documentation to evidence a usability evaluation of an interface.
   	}
        \gradespan{5}{Submission is timely.
        	\par Enough work is available to hold a meaningful discussion.
	\par Clear evidence of a `reasonable' evaluation process.
	\par Clear evidence of usability testing knowledge and communication skills.
	\par Clear evidence of a synthesis of findings.
	\par No breaches of academic integrity.}
% UNFINISHED
    \criterion{Appropriateness of chosen evaluation methods}{10\%}
        \grade\fail 	No evaluation methods have been implemented.
        \grade 		At least one method has been implemented.
        \grade 		At least one method has been implemented.
        \par		The approach is appropriate. 
        \grade 		Two methods have been implemented 
        \par		The approach is reasonably appropriate.
        \grade 		Two methods have been implemented.
        \par		The approach is appropriate.
        \par 		There is some consideration for 
        \grade 		Two methods have been implemented.
        \par		The approach is appropriate.
        \par		The approach is considered and clearly justified.
% UNFINISHED Needs moving up two qualifiers? Might need more detail
    \criterion{Adequacy of Analysis of Findings}{20\%}
        \grade\fail 	No analysis has been presented.
        
        \grade 		Little analysis has been presented.
        \grade 		Some analysis has been presented. 
        \grade 		Much analysis has been presented.
        \grade 		Considerable analysis has been presented.
        \grade 		Significant analysis has been presented.
% DONE
    \criterion{Synthesis}{15\%}
        \grade\fail No connections are made between the findings.
        \grade		Superficial connections are made between the findings.
        \grade		Basic connections are made between the findings from the different evaluation methods.
        \grade		Reasonable connections are made the findings from the different evaluation methods.
        \par		Connections go beyond mere description.
        \grade		Strong connections are made between the findings from the different evaluation methods.
        \par		Connections are analytical in nature.
        \grade		Strong connections are made between the findings from the different evaluation methods.
        \par		Connections are analytical and evaluative in nature.
% UNFINISHED Needs moving up two qualifiers?
    \criterion{Quality of Documentation \& Presentation}{10\%}
        \grade\fail There is no documentation. 
        \grade There is some basic documentation.
        \grade There is little documentation.
        \grade There is much documentation.
            \par Some images and diagrams have been included.
        \grade There is considerable documentation
            \par The use of images and diagrams is effective.
            \par Some dynamic content has been included.
        \grade There is significant documentation.
            \par The use of images and diagrams is effective.
            \par dynamic content is effective and helps to articulate the process and findings. 
% DONE
    \criterion{Specificity, Verifiability, \& Accuracy of Claims}{5\%}
        \grade\fail 	No documentation to evidence to claims.
        \par 		Substantial errors and/or misinterpretations.
        \grade 		Few claims have supporting documentation.
        \par 		Significant errors and/or misinterpretations.
        \grade 		Some claims have supporting documentation.
        \par 		Many errors and/or misinterpretations.
        \grade 		Many claims have supporting documentation.
        \par 		Some errors and/or misinterpretations.
        \grade 		Most claims have supporting documentation.
        \par 		Few errors and/or misinterpretations.
        \grade 		All claims have a supporting documentation
        \par 		Almost no errors and/or misinterpretations.
% DONE
   \criterion{Depth of insight}{15\%}
        	\grade\fail No insight is demonstrated.
        \par		Findings are merely presented.
        \grade		Little insight is demonstrated.
        \par		Findings are summarised.
        \grade		Some insight is demonstrated.
        \par		Attempts are made at discussion beyond summary.
        \grade		Much insight is demonstrated.
        \par		Discussion is inferential in nature.
        \grade		Considerable insight is demonstrated.
        \par		Discussion is analytical in nature.
        \grade		Significant insight is demonstrated.
        \par		Discussion is analytical and evaluative in nature.
\end{markingrubric}

\end{document}
